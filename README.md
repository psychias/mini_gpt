# mini_gpt
MiniGPT is a lightweight, self-contained implementation of a GPT-style transformer built entirely in PyTorch, without relying on external deep learning libraries like transformers. This project serves as an educational tool for understanding the inner workings of transformers, self-attention, and language modeling.
